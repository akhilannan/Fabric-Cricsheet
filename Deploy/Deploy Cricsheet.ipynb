{"cells":[{"cell_type":"markdown","source":["# Install Semantic Link"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"b41deb69-dc33-4d24-8b8c-aa488095ceb1"},{"cell_type":"code","source":["!pip install semantic-link -q"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"215cc325-49d9-4537-860f-7783fbf9fe76"},{"cell_type":"markdown","source":["# Initialize Lakehouse Names"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"d4dcac19-cb91-43a5-83b7-9b568bca95d3"},{"cell_type":"code","source":["raw_lakehouse = \"lh_bronze\"\n","clean_lakehouse = \"lh_gold\""],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"tags":["parameters"]},"id":"6777d5f2-9861-4a89-bb42-f985b96c4aa4"},{"cell_type":"markdown","source":["# Set Git Links"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"ad1b9506-fe8d-43c0-b766-d64596e90fea"},{"cell_type":"code","source":["REPO_NAME = \"Fabric-Cricsheet\"\n","MAIN_NAME = f\"/{REPO_NAME}-main\"\n","GITHUB_REPO_ZIP = f\"https://github.com/akhilannan/{REPO_NAME}/archive/refs/heads/main.zip\"\n","SEMANTIC_MODEL = \"Cricsheet Model\"\n","REPORT_NAME = \"Cricsheet Analysis\"\n","BIM_PATH = f\"{MAIN_NAME}/Semantic Model/{SEMANTIC_MODEL}.bim\"\n","REPORT_PATH = f\"{MAIN_NAME}/Power BI Report/{REPORT_NAME}.Report/report.json\"\n","NOTEBOOK_PATH = f\"{MAIN_NAME}/Notebooks\"\n","UTILITY_PATH = f\"{MAIN_NAME}/Utility Functions\"\n","FABRIC_UTILS_FILE_NAME = \"fabric_utils.py\""],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"9b08b82a-bb73-4b8b-877f-3d68581068df"},{"cell_type":"markdown","source":["# Create Mount Points"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"10aa4387-4dc2-49b3-b7f5-3ac561772698"},{"cell_type":"code","source":["lakehouses = {raw_lakehouse: None, clean_lakehouse: None}\n","for lh in lakehouses:\n","    try:\n","        # Attempt to create the lakehouse and update the dictionary if successful\n","        lakehouse_details = mssparkutils.lakehouse.create(lh)\n","    except:\n","        # If creation fails, get the existing lakehouse and update the dictionary\n","        lakehouse_details = mssparkutils.lakehouse.get(lh)\n","    workspace_id = lakehouse_details.workspaceId\n","    lakehouse_id = lakehouse_details.id\n","    abfss_lakehouse_path = f\"abfss://{workspace_id}@onelake.dfs.fabric.microsoft.com/{lakehouse_id}\"\n","    mount_point = f\"/lakehouse/{lh}\"\n","    mssparkutils.fs.mount(abfss_lakehouse_path, mount_point)\n","    lakehouses[lh] = mssparkutils.fs.getMountPath(mount_point)\n"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":true},"nteract":{"transient":{"deleting":false}},"collapsed":false},"id":"f214df35-5672-4630-8ba5-180f1a50eb1f"},{"cell_type":"markdown","source":["# Initialize Variables"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"8b83869e-24ba-41d4-b5c4-6cb44256dc62"},{"cell_type":"code","source":["import os\n","files_path = \"/Files\"\n","lh_files_raw_path = lakehouses[raw_lakehouse] + files_path\n","lh_git_raw_path = lh_files_raw_path + \"/git\"\n","lh_bim_path = lh_git_raw_path + BIM_PATH\n","lh_report_path = lh_git_raw_path + REPORT_PATH\n","lh_git_notebook_path = lh_git_raw_path + NOTEBOOK_PATH\n","git_utils_path = lh_files_raw_path + \"/git\" + UTILITY_PATH + \"/\" + FABRIC_UTILS_FILE_NAME\n","package_path = os.path.join(lh_files_raw_path, \"packages\")\n","fabric_path = os.path.join(package_path, \"fabric_python_functions\")\n","fabric_utils_path = os.path.join(fabric_path, \"fabric_utils\")"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"6fbe1b67-54b0-465c-b510-00bdd69a46b7"},{"cell_type":"markdown","source":["# Download Git Repo contents as Zip and Unzip it"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"02df99c7-fb13-4833-b0dd-69091d97fd32"},{"cell_type":"code","source":["import requests\n","import zipfile\n","import io\n","import shutil\n","\n","shutil.rmtree(lh_git_raw_path, ignore_errors=True)\n","r = requests.get(GITHUB_REPO_ZIP)\n","z = zipfile.ZipFile(io.BytesIO(r.content))\n","z.extractall(lh_git_raw_path)"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"79dc300b-eebe-4438-a96b-9962f37949af"},{"cell_type":"markdown","source":["# Add and Import Fabric Utilities"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"07dc64cd-95a6-4f35-a07e-9740cc508386"},{"cell_type":"code","source":["sc.addPyFile(git_utils_path)\n","import fabric_utils as U"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"d9eddcf7-d194-498d-b8ed-ebfdecc2a834"},{"cell_type":"markdown","source":["# Create Wheel Package"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"a99f1e45-4781-4b10-a073-00a640cd81eb"},{"cell_type":"code","source":["import subprocess\n","import sys\n","\n","# Remove the existing package directory and create a new one\n","shutil.rmtree(package_path, ignore_errors=True)\n","os.makedirs(fabric_utils_path, exist_ok=True)\n","\n","# Write the Python code to the functions.py file\n","python_file_path = os.path.join(fabric_utils_path, 'functions.py')\n","shutil.copyfile(git_utils_path, python_file_path)\n","\n","# Extract the function names to a list\n","function_names =[]\n","with open(python_file_path, 'r') as file:\n","    for line in file:\n","        # Check if the line contains a function definition\n","        if line.startswith('def '):\n","            # Extract the function name\n","            function_name = line.split('def ')[1].split('(')[0]\n","            function_names.append(function_name)\n","\n","# Write the __init__.py content\n","init_content = \"\\n\".join(f\"from .functions import {name}\" for name in function_names)\n","init_file_path = os.path.join(fabric_utils_path, '__init__.py')\n","with open(init_file_path, 'w') as init_file:\n","    init_file.write(init_content)\n","\n","# Write the setup.py content\n","setup_content = \"\"\"\n","from setuptools import setup, find_packages\n","\n","setup(\n","name='fabric_utils',\n","version='0.1',\n","packages=find_packages(),\n","install_requires=['semantic-link'],\n",")\n","\"\"\"\n","setup_file_path = os.path.join(fabric_path, 'setup.py')\n","with open(setup_file_path, 'w') as setup_file:\n","    setup_file.write(setup_content)\n","\n","# Build the wheel file\n","os.chdir(fabric_path)\n","subprocess.check_call([sys.executable, 'setup.py', 'sdist', 'bdist_wheel'])\n","\n","# Move the wheel file outside the 'fabric_utils' folder\n","wheel_files = [f for f in os.listdir('dist') if f.endswith('.whl')]\n","for file in wheel_files:\n","    shutil.move(f'dist/{file}', f'../{file}')\n","\n","# Clean up the package directory\n","shutil.rmtree(fabric_path)\n","\n","# Print a success message\n","print(\"The wheel file has been successfully created and moved outside the 'fabric_utils' folder.\")\n"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":true},"nteract":{"transient":{"deleting":false}}},"id":"6abde91b-7712-45bb-81c8-e9f6e745f171"},{"cell_type":"markdown","source":["# Copy Wheel file to Clean Lakehouse"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"fb14c69c-2df6-480b-9cad-5b939a7f8b38"},{"cell_type":"code","source":["clean_package_path = package_path.replace(raw_lakehouse, clean_lakehouse)\n","if os.path.exists(clean_package_path):\n","        shutil.rmtree(clean_package_path)\n","shutil.copytree(package_path, clean_package_path)"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"ac4ddbaa-4624-4bf3-bc9d-ce0c37125a1d"},{"cell_type":"markdown","source":["# Deploy Notebook"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"492d69c3-5e35-4e28-afe8-99e68de08b49"},{"cell_type":"code","source":["import json\n","\n","# Define the code replacements using formatted strings\n","code_replacements = {\n","    'RAW_LAKEHOUSE = \"lh_bronze\"': f'RAW_LAKEHOUSE = \"{raw_lakehouse}\"',\n","    'CLEAN_LAKEHOUSE = \"lh_gold\"': f'CLEAN_LAKEHOUSE = \"{clean_lakehouse}\"'\n","}\n","\n","# Define the mapping of notebook names to their respective default lakehouse\n","notebook_lakehouse = {\n","    'Cricsheet Orchestrator': raw_lakehouse,\n","    'Cricsheet Initialize': raw_lakehouse,\n","    'Cricsheet Ingest Data': raw_lakehouse,\n","    'Cricsheet Build Facts and Dimensions': clean_lakehouse,\n","    'Cricsheet Model Refresh': clean_lakehouse,\n","    'Cricsheet Optimize and Vacuum': raw_lakehouse\n","}\n","\n","# Iterate over the notebook_lakehouse dictionary and process each notebook\n","for file_name, lakehouse_type in notebook_lakehouse.items():\n","    full_file_name = file_name + \".ipynb\"\n","    file_path = os.path.join(lh_git_notebook_path , full_file_name)\n","    with open(file_path, 'r') as file:\n","        notebook_json = json.load(file)\n","    U.create_or_replace_notebook_from_ipynb(file_name, notebook_json, lakehouse_type, code_replacements)"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"7935622a-9e10-483f-9970-64fd83a96dc9"},{"cell_type":"markdown","source":["# Deploy Semantic Model"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"9f6ded29-5c75-4348-9632-850aa83d6bbc"},{"cell_type":"code","source":["with open(lh_bim_path, 'r') as file:\n","        bim_json = json.load(file)\n","U.execute_with_retries(U.create_or_replace_semantic_model_from_bim,\n","                     dataset_name=SEMANTIC_MODEL,\n","                     bim_file_json=bim_json)"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"4b967ee7-e62a-4959-948d-79b20436f3c3"},{"cell_type":"markdown","source":["# Update Semantic Model Connection"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"bd82ce92-c688-4239-9b21-7ef1199ec4ea"},{"cell_type":"code","source":["U.execute_with_retries(U.update_model_expression,\n","                     dataset_name=SEMANTIC_MODEL,\n","                     lakehouse_name=clean_lakehouse)"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"8caaf622-d0a3-4cfe-8737-1e3db0b0e12d"},{"cell_type":"markdown","source":["# Deploy Report and Repoint to the Semantic Model"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"f1f6695a-a533-4a6b-9413-fbfffb33c58e"},{"cell_type":"code","source":["with open(lh_report_path, 'r') as file:\n","        report_json = json.load(file)\n","U.execute_with_retries(U.create_or_replace_report_from_reportjson,\n","                     report_name=REPORT_NAME,\n","                     dataset_name=SEMANTIC_MODEL,\n","                     report_json=report_json)"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"b73e8772-6e3f-42b8-8ebd-7b74b5862139"}],"metadata":{"language_info":{"name":"python"},"kernel_info":{"name":"synapse_pyspark"},"microsoft":{"language":"python"},"widgets":{},"kernelspec":{"name":"synapse_pyspark","language":"Python","display_name":"Synapse PySpark"},"nteract":{"version":"nteract-front-end@1.0.0"},"synapse_widget":{"version":"0.1","state":{}},"spark_compute":{"compute_id":"/trident/default"},"dependencies":{"lakehouse":{}}},"nbformat":4,"nbformat_minor":5}