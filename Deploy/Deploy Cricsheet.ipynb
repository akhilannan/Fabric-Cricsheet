{"cells":[{"cell_type":"code","execution_count":null,"id":"b81b0bd0","metadata":{},"outputs":[],"source":["import sys\n","import os"]},{"cell_type":"markdown","id":"cb34877d","metadata":{},"source":["# Check if running on Fabric"]},{"cell_type":"code","execution_count":null,"id":"ce703a2e","metadata":{},"outputs":[],"source":["is_fabric = 'notebookutils' in sys.modules"]},{"cell_type":"markdown","id":"d4dcac19-cb91-43a5-83b7-9b568bca95d3","metadata":{"nteract":{"transient":{"deleting":false}}},"source":["# Initialize Variables"]},{"cell_type":"code","execution_count":null,"id":"6777d5f2-9861-4a89-bb42-f985b96c4aa4","metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"nteract":{"transient":{"deleting":false}},"tags":["parameters"]},"outputs":[],"source":["# Common configurations\n","raw_lakehouse = \"lh_bronze\"\n","clean_lakehouse = \"lh_gold\"\n","workspace_name = \"Cricsheet\" # Target workspace name where the artifacts will be deployed\n","capacity_id = None # None will pick a random capacity which the user has access to\n","start_dataload = True # False if you don't want to start data load\n","wait_for_dataload_completion = True # False if you don't want to wait for the completion of job\n","# Authentication variables (required when running outside Fabric)\n","tenant_id = os.getenv('tenant_id') or None\n","client_id = os.getenv('generic_client_id') or None\n","client_secret = None\n","username = os.getenv('azure_username') or None\n","password = os.getenv('azure_password') or None"]},{"cell_type":"markdown","id":"82bd5f72-f716-4202-936f-7818893e5a3b","metadata":{"nteract":{"transient":{"deleting":false}}},"source":["# Constants"]},{"cell_type":"code","execution_count":null,"id":"3d76640c","metadata":{},"outputs":[],"source":["REPO_NAME = \"Fabric-Cricsheet\"\n","BRANCH = \"main\"\n","ENV_PATH = \"/Environment\"\n","NOTEBOOK_PATH = \"/Notebooks\"\n","ENV_NAME = \"cricsheet-environment\"\n","SPARK_CONFIG_FILE = \"SparkCompute.json\"\n","UTILS = [\n","    \"api_client\",\n","    \"fabric_utils\",\n","    \"delta_table_operations\",\n","    \"file_operations\",\n","    \"job_operations\",\n","    \"powerbi_operations\",\n","    \"environment_operations\"\n","]\n","UTILS_PY = [util + \".py\" for util in UTILS]\n","CRICSHEET = {\"Cricsheet Model\": [\"Cricsheet Analysis\"]}\n","DATALOAD = {\"Data Load Model\": [\"Data Load Monitor\"]}"]},{"cell_type":"markdown","id":"580a087a","metadata":{},"source":["# Fabric-specific configurations"]},{"cell_type":"code","execution_count":null,"id":"dfe20bcb","metadata":{},"outputs":[],"source":["if is_fabric:\n","    REPO_BRANCH_NAME = f\"/{REPO_NAME}-{BRANCH}\"\n","    ROOT_DOWNLOAD_FOLDER = \"git\"\n","    GITHUB_REPO = f\"https://github.com/akhilannan/{REPO_NAME}\"\n","    GITHUB_RAW = f\"/raw/{BRANCH}\"\n","    ZIP_FILE_NAME = f\"{BRANCH}.zip\"\n","    GITHUB_REPO_ZIP = f\"{GITHUB_REPO}/archive/refs/heads/{ZIP_FILE_NAME}\"\n","\n","    # Add utility files to Spark context\n","    git_url_files = [\n","        GITHUB_REPO + GITHUB_RAW + ENV_PATH + \"/\" + util for util in UTILS_PY\n","    ]\n","    for git_url_file in git_url_files:\n","        sc.addPyFile(git_url_file)\n","else:\n","    # Local-specific configurations\n","    sys.path.append(os.path.abspath(os.path.join(\"..\", \"Environment\")))"]},{"cell_type":"markdown","id":"af160374","metadata":{},"source":["# Import Libraries"]},{"cell_type":"code","execution_count":null,"id":"dc9b07cf","metadata":{},"outputs":[],"source":["from api_client import FabricPowerBIClient\n","import fabric_utils as U\n","import file_operations as L\n","import job_operations as J\n","import powerbi_operations as P\n","import environment_operations as E"]},{"cell_type":"markdown","id":"d06eccf5-be37-4955-b2bc-60478979eed5","metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"},"nteract":{"transient":{"deleting":false}}},"source":["# Initialize Fabric Client"]},{"cell_type":"code","execution_count":null,"id":"db5ad7f0-d771-460b-a2e1-c682bb318512","metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"nteract":{"transient":{"deleting":false}}},"outputs":[],"source":["fabric_client = FabricPowerBIClient(\n","    tenant_id=tenant_id,\n","    client_id=client_id,\n","    client_secret=client_secret,\n","    username=username,\n","    password=password,\n","    client_type=\"FabricRestClient\"\n",")"]},{"cell_type":"markdown","id":"33c58871-84f3-48b1-8ba2-c80a52e44910","metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"},"nteract":{"transient":{"deleting":false}}},"source":["# Create Workspace if not exists"]},{"cell_type":"code","execution_count":null,"id":"9107d1d3-33b2-41b8-a46b-e7715fcd1192","metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"nteract":{"transient":{"deleting":false}}},"outputs":[],"source":["workspace_id = U.get_or_create_fabric_workspace(workspace_name=workspace_name, capacity_id=capacity_id, client=fabric_client)"]},{"cell_type":"markdown","id":"077c8b29-448b-4b3d-9597-4d1bdd3d146a","metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"},"nteract":{"transient":{"deleting":false}}},"source":["# Semantic Models and Reports Structure"]},{"cell_type":"code","execution_count":null,"id":"b8b0f4c6","metadata":{},"outputs":[],"source":["lh_semantic_reports = {\n","    clean_lakehouse: CRICSHEET,\n","    raw_lakehouse: DATALOAD\n","}"]},{"cell_type":"markdown","id":"0e9e0bd9","metadata":{},"source":["# Fabric-specific operations"]},{"cell_type":"code","execution_count":null,"id":"d1e2ca30","metadata":{},"outputs":[],"source":["if is_fabric:\n","    # Set Lakehouse Path\n","    lakehouses = {}\n","    for lh in lh_semantic_reports:\n","        lakehouses[lh] = U.get_lakehouse_path(\n","            lakehouse_name=lh,\n","            path_type=\"local\",\n","            folder_type=\"Files\",\n","            workspace=workspace_id,\n","            client=fabric_client\n","        )\n","\n","    lh_repo_path = (\n","        lakehouses[raw_lakehouse] + \"/\" + ROOT_DOWNLOAD_FOLDER + REPO_BRANCH_NAME\n","    )\n","    lh_git_notebook_path = lh_repo_path + NOTEBOOK_PATH\n","    lh_git_env_path = lh_repo_path + ENV_PATH\n","    spark_config_path = lh_git_env_path + \"/\" + SPARK_CONFIG_FILE\n","    utils_files = [lh_git_env_path + \"/\" + util for util in UTILS_PY]\n","\n","    # Download Git Repo contents as Zip and Unzip it\n","    zip_file_path = L.download_data(\n","        url=GITHUB_REPO_ZIP,\n","        lakehouse=raw_lakehouse,\n","        path=ROOT_DOWNLOAD_FOLDER,\n","        workspace=workspace_id,\n","        client=fabric_client\n","    )\n","    L.unzip_files(zip_file_path)\n","else:\n","    # Local-specific paths\n","    env_base_path = f\"..{ENV_PATH}\"\n","    spark_config_path = f\"{env_base_path}/{SPARK_CONFIG_FILE}\"\n","    utils_files = [env_base_path + \"/\" + util for util in UTILS_PY]\n","    lh_git_notebook_path = f\"..{NOTEBOOK_PATH}\"\n"]},{"cell_type":"markdown","id":"9c4b855e-707a-4fb1-aa01-f1b07a489d3b","metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"},"nteract":{"transient":{"deleting":false}}},"source":["# Create and Publish Spark Environment"]},{"cell_type":"code","execution_count":null,"id":"c1299cba-4d21-4ad1-b33e-8c6dc70a8814","metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"nteract":{"transient":{"deleting":false}}},"outputs":[],"source":["E.create_and_publish_spark_environment(\n","    environment_name=ENV_NAME,\n","    json_path=spark_config_path,\n","    py_path=utils_files,\n","    workspace=workspace_id,\n","    client=fabric_client\n",")"]},{"cell_type":"markdown","id":"492d69c3-5e35-4e28-afe8-99e68de08b49","metadata":{"nteract":{"transient":{"deleting":false}}},"source":["# Deploy Notebooks"]},{"cell_type":"code","execution_count":null,"id":"7935622a-9e10-483f-9970-64fd83a96dc9","metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"nteract":{"transient":{"deleting":false}}},"outputs":[],"source":["# Code replacements\n","code_replacements = {\n","    'RAW_LAKEHOUSE = \"lh_bronze\"': f'RAW_LAKEHOUSE = \"{raw_lakehouse}\"',\n","    'CLEAN_LAKEHOUSE = \"lh_gold\"': f'CLEAN_LAKEHOUSE = \"{clean_lakehouse}\"'\n","}\n","\n","# Notebook to lakehouse mapping\n","notebook_lakehouse = {\n","    \"Cricsheet Orchestrator\": raw_lakehouse,\n","    \"Cricsheet Initialize\": raw_lakehouse,\n","    \"Cricsheet Ingest Data\": raw_lakehouse,\n","    \"Cricsheet Build Facts and Dimensions\": clean_lakehouse,\n","    \"Cricsheet Model Refresh\": clean_lakehouse,\n","    \"Cricsheet Optimize and Vacuum\": raw_lakehouse\n","}\n","\n","# Process notebooks\n","for file_name, lakehouse_type in notebook_lakehouse.items():\n","    file_path = lh_git_notebook_path + \"/\" + file_name + \".ipynb\"\n","    E.create_or_replace_notebook_from_ipynb(\n","        notebook_path=file_path,\n","        default_lakehouse_name=lakehouse_type,\n","        environment_name=ENV_NAME,\n","        replacements=code_replacements,\n","        workspace=workspace_id,\n","        client=fabric_client\n","    )"]},{"cell_type":"markdown","id":"3a5c16bd-67dc-4ec8-b14f-d36ed2883e81","metadata":{"nteract":{"transient":{"deleting":false}}},"source":["# Deploy Semantic Models and Reports"]},{"cell_type":"code","execution_count":null,"id":"80a16167-9e76-485b-a37e-bc451ae3492b","metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"nteract":{"transient":{"deleting":false}}},"outputs":[],"source":["# Set Variables for Semantic Model and Report\n","base_path = lh_repo_path if is_fabric else \"..\"\n","semantic_model_report = [\n","    {\n","        'lakehouse_name': lakehouse,\n","        'semantic_model': model,\n","        'semantic_model_path': f\"{base_path}/Semantic Model/{model}.SemanticModel\",\n","        'report_path': f\"{base_path}/Power BI Report/{report}.Report\"\n","    }\n","    for lakehouse, models in lh_semantic_reports.items()\n","    for model, reports in models.items()\n","    for report in reports\n","]\n","\n","# Deploy models and reports\n","for smr in semantic_model_report:\n","    P.create_or_replace_semantic_model(\n","        model_path=smr[\"semantic_model_path\"],\n","        lakehouse_name=smr[\"lakehouse_name\"],\n","        workspace=workspace_id,\n","        client=fabric_client\n","    )\n","    P.create_or_replace_report_from_pbir(\n","        report_path=smr[\"report_path\"],\n","        dataset_name=smr[\"semantic_model\"],\n","        dataset_workspace=workspace_id,\n","        report_workspace=workspace_id,\n","        client=fabric_client\n","    )"]},{"cell_type":"markdown","id":"4fc5bd16-bfc0-411a-b1d6-04a1bc20f4bb","metadata":{"nteract":{"transient":{"deleting":false}}},"source":["# Delete Git folder"]},{"cell_type":"code","execution_count":null,"id":"d6d874f0-8556-4ac6-9ab3-03eedc12b07a","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":true,"source_hidden":false},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"nteract":{"transient":{"deleting":false}}},"outputs":[],"source":["if is_fabric:\n","    L.delete_folder_from_lakehouse(\n","        lakehouse=raw_lakehouse,\n","        path=ROOT_DOWNLOAD_FOLDER,\n","        workspace=workspace_id,\n","        client=fabric_client\n","    )"]},{"cell_type":"markdown","id":"dcbff0b4-d253-42cc-88cb-210d22b61604","metadata":{"nteract":{"transient":{"deleting":false}}},"source":["# Start Data Load"]},{"cell_type":"code","execution_count":null,"id":"a49aaaec-57a1-44c2-b5ff-4784b000bbc2","metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"nteract":{"transient":{"deleting":false}}},"outputs":[],"source":["if start_dataload:\n","    J.run_notebook_job(\n","        notebook_name=\"Cricsheet Orchestrator\",\n","        wait_for_completion=wait_for_dataload_completion,\n","        workspace=workspace_id,\n","        client=fabric_client\n","    )"]}],"metadata":{"dependencies":{"lakehouse":{}},"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.5"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"nteract":{"version":"nteract-front-end@1.0.0"},"spark_compute":{"compute_id":"/trident/default"},"synapse_widget":{"state":{},"version":"0.1"},"widgets":{}},"nbformat":4,"nbformat_minor":5}
