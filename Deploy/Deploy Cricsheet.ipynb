{"cells":[{"cell_type":"code","execution_count":1,"id":"b81b0bd0","metadata":{},"outputs":[],"source":["import sys\n","import os"]},{"cell_type":"markdown","id":"cb34877d","metadata":{},"source":["# Check if running on Fabric"]},{"cell_type":"code","execution_count":2,"id":"ce703a2e","metadata":{},"outputs":[],"source":["is_fabric = 'notebookutils' in sys.modules"]},{"cell_type":"markdown","id":"d4dcac19-cb91-43a5-83b7-9b568bca95d3","metadata":{"nteract":{"transient":{"deleting":false}}},"source":["# Initialize Variables"]},{"cell_type":"code","execution_count":3,"id":"6777d5f2-9861-4a89-bb42-f985b96c4aa4","metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"nteract":{"transient":{"deleting":false}},"tags":["parameters"]},"outputs":[],"source":["# Common configurations\n","lakehouse_name = \"lh_cricsheet\"\n","staging_schema = \"staging\"\n","reporting_schema = \"reporting\"\n","log_schema = \"logs\"\n","workspace_name = \"Cricsheet\" # Target workspace name where the artifacts will be deployed\n","capacity_id = None # None will pick a random capacity which the user has access to\n","start_dataload = True # False if you don't want to start data load\n","wait_for_dataload_completion = True # False if you don't want to wait for the completion of job\n","# Authentication variables (required when running outside Fabric)\n","tenant_id = os.getenv('tenant_id') or None\n","client_id = os.getenv('generic_client_id') or None\n","client_secret = None\n","username = os.getenv('azure_username') or None\n","password = os.getenv('azure_password') or None"]},{"cell_type":"markdown","id":"82bd5f72-f716-4202-936f-7818893e5a3b","metadata":{"nteract":{"transient":{"deleting":false}}},"source":["# Constants"]},{"cell_type":"code","execution_count":4,"id":"3d76640c","metadata":{},"outputs":[],"source":["REPO_NAME = \"Fabric-Cricsheet\"\n","BRANCH = \"main\"\n","ENV_PATH = \"/Environment\"\n","NOTEBOOK_PATH = \"/Notebooks\"\n","ENV_NAME = \"cricsheet-environment\"\n","SPARK_CONFIG_FILE = \"SparkCompute.json\"\n","UTILS = [\n","    \"api_client\",\n","    \"fabric_utils\",\n","    \"delta_table_operations\",\n","    \"file_operations\",\n","    \"job_operations\",\n","    \"powerbi_operations\",\n","    \"environment_operations\"\n","]\n","UTILS_PY = [util + \".py\" for util in UTILS]\n","MODELS_AND_REPORTS = [\n","    {\n","        \"model\": \"Cricsheet Model\",\n","        \"reports\": [\"Cricsheet Analysis\"],\n","    },\n","    {\n","        \"model\": \"Data Load Model\",\n","        \"reports\": [\"Data Load Monitor\"],\n","    },\n","]"]},{"cell_type":"markdown","id":"580a087a","metadata":{},"source":["# Fabric-specific configurations"]},{"cell_type":"code","execution_count":5,"id":"dfe20bcb","metadata":{},"outputs":[],"source":["if is_fabric:\n","    REPO_BRANCH_NAME = f\"/{REPO_NAME}-{BRANCH}\"\n","    ROOT_DOWNLOAD_FOLDER = \"git\"\n","    GITHUB_REPO = f\"https://github.com/akhilannan/{REPO_NAME}\"\n","    GITHUB_RAW = f\"/raw/{BRANCH}\"\n","    ZIP_FILE_NAME = f\"{BRANCH}.zip\"\n","    GITHUB_REPO_ZIP = f\"{GITHUB_REPO}/archive/refs/heads/{ZIP_FILE_NAME}\"\n","\n","    # Add utility files to Spark context\n","    git_url_files = [\n","        GITHUB_REPO + GITHUB_RAW + ENV_PATH + \"/\" + util for util in UTILS_PY\n","    ]\n","    for git_url_file in git_url_files:\n","        sc.addPyFile(git_url_file)\n","else:\n","    # Local-specific configurations\n","    sys.path.append(os.path.abspath(os.path.join(\"..\", \"Environment\")))"]},{"cell_type":"markdown","id":"af160374","metadata":{},"source":["# Import Libraries"]},{"cell_type":"code","execution_count":6,"id":"dc9b07cf","metadata":{},"outputs":[],"source":["from api_client import AzureAPIClient\n","import fabric_utils as U\n","import file_operations as L\n","import job_operations as J\n","import powerbi_operations as P\n","import environment_operations as E"]},{"cell_type":"markdown","id":"d06eccf5-be37-4955-b2bc-60478979eed5","metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"},"nteract":{"transient":{"deleting":false}}},"source":["# Initialize Fabric Client"]},{"cell_type":"code","execution_count":7,"id":"db5ad7f0-d771-460b-a2e1-c682bb318512","metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"nteract":{"transient":{"deleting":false}}},"outputs":[],"source":["fabric_client = AzureAPIClient(\n","    tenant_id=tenant_id,\n","    client_id=client_id,\n","    client_secret=client_secret,\n","    username=username,\n","    password=password,\n","    client_type=\"FabricRestClient\"\n",")"]},{"cell_type":"markdown","id":"33c58871-84f3-48b1-8ba2-c80a52e44910","metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"},"nteract":{"transient":{"deleting":false}}},"source":["# Create Workspace if not exists"]},{"cell_type":"code","execution_count":8,"id":"9107d1d3-33b2-41b8-a46b-e7715fcd1192","metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"nteract":{"transient":{"deleting":false}}},"outputs":[],"source":["workspace_id = U.get_or_create_fabric_workspace(\n","    workspace_name=workspace_name, capacity_id=capacity_id, client=fabric_client\n",")"]},{"cell_type":"markdown","id":"0e9e0bd9","metadata":{},"source":["# Fabric-specific operations"]},{"cell_type":"code","execution_count":9,"id":"d1e2ca30","metadata":{},"outputs":[],"source":["if is_fabric:\n","    # Set Lakehouse Path\n","    lakehouse_path = U.get_lakehouse_path(\n","        lakehouse_name=lakehouse_name,\n","        path_type=\"local\",\n","        folder_type=\"Files\",\n","        workspace=workspace_id,\n","        client=fabric_client,\n","    )\n","\n","    lh_repo_path = lakehouse_path + \"/\" + ROOT_DOWNLOAD_FOLDER + REPO_BRANCH_NAME\n","    lh_git_notebook_path = lh_repo_path + NOTEBOOK_PATH\n","    lh_git_env_path = lh_repo_path + ENV_PATH\n","    spark_config_path = lh_git_env_path + \"/\" + SPARK_CONFIG_FILE\n","    utils_files = [lh_git_env_path + \"/\" + util for util in UTILS_PY]\n","\n","    # Download Git Repo contents as Zip and Unzip it\n","    zip_file_path = L.download_data(\n","        url=GITHUB_REPO_ZIP,\n","        lakehouse=lakehouse_name,\n","        path=ROOT_DOWNLOAD_FOLDER,\n","        workspace=workspace_id,\n","        client=fabric_client,\n","    )\n","    L.unzip_files(zip_file_path)\n","else:\n","    # Local-specific paths\n","    env_base_path = f\"..{ENV_PATH}\"\n","    spark_config_path = f\"{env_base_path}/{SPARK_CONFIG_FILE}\"\n","    utils_files = [env_base_path + \"/\" + util for util in UTILS_PY]\n","    lh_git_notebook_path = f\"..{NOTEBOOK_PATH}\""]},{"cell_type":"markdown","id":"9c4b855e-707a-4fb1-aa01-f1b07a489d3b","metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"},"nteract":{"transient":{"deleting":false}}},"source":["# Create and Publish Spark Environment"]},{"cell_type":"code","execution_count":null,"id":"c1299cba-4d21-4ad1-b33e-8c6dc70a8814","metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"nteract":{"transient":{"deleting":false}}},"outputs":[],"source":["E.create_and_publish_spark_environment(\n","    environment_name=ENV_NAME,\n","    json_path=spark_config_path,\n","    py_path=utils_files,\n","    workspace=workspace_id,\n","    client=fabric_client\n",")"]},{"cell_type":"markdown","id":"492d69c3-5e35-4e28-afe8-99e68de08b49","metadata":{"nteract":{"transient":{"deleting":false}}},"source":["# Deploy Notebooks"]},{"cell_type":"code","execution_count":null,"id":"54c4f3af","metadata":{},"outputs":[],"source":["replacements = {\n","    r'LAKEHOUSE\\s*=\\s*\"[^\"]*\"': f'LAKEHOUSE = \"{lakehouse_name}\"',\n","    r'STAGING_SCHEMA\\s*=\\s*\"[^\"]*\"': f'STAGING_SCHEMA = \"{staging_schema}\"',\n","    r'REPORTING_SCHEMA\\s*=\\s*\"[^\"]*\"': f'REPORTING_SCHEMA = \"{reporting_schema}\"',\n","    r'LOG_SCHEMA\\s*=\\s*\"[^\"]*\"': f'LOG_SCHEMA = \"{log_schema}\"',\n","}\n","\n","notebook_prefixes = {\n","    \"Cricsheet Orchestrator\": None,\n","    \"Cricsheet Initialize\": replacements,\n","    \"Cricsheet Ingest Data\": None,\n","    \"Cricsheet Build Facts and Dimensions\": None,\n","    \"Cricsheet Model Refresh\": None,\n","    \"Cricsheet Optimize and Vacuum\": None,\n","}\n","\n","for file_name_prefix, notebook_replacements in notebook_prefixes.items():\n","    file_path = os.path.join(lh_git_notebook_path, f\"{file_name_prefix}.ipynb\")\n","\n","    E.create_or_replace_notebook_from_ipynb(\n","        notebook_path=file_path,\n","        default_lakehouse_name=lakehouse_name,\n","        environment_name=ENV_NAME,\n","        replacements=notebook_replacements,\n","        workspace=workspace_id,\n","        client=fabric_client,\n","    )"]},{"cell_type":"markdown","id":"3a5c16bd-67dc-4ec8-b14f-d36ed2883e81","metadata":{"nteract":{"transient":{"deleting":false}}},"source":["# Deploy Semantic Models and Reports"]},{"cell_type":"code","execution_count":null,"id":"80a16167-9e76-485b-a37e-bc451ae3492b","metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"nteract":{"transient":{"deleting":false}}},"outputs":[],"source":["base_path = lh_repo_path if is_fabric else \"..\"\n","\n","for config in MODELS_AND_REPORTS:\n","    # Add schema mapping\n","    if config[\"model\"] == \"Data Load Model\":\n","        config[\"schema\"] = log_schema\n","    else:\n","        config[\"schema\"] = reporting_schema\n","\n","    # Deploy semantic model\n","    P.create_or_replace_semantic_model(\n","        model_path=f\"{base_path}/Semantic Model/{config['model']}.SemanticModel\",\n","        lakehouse_name=lakehouse_name,\n","        schema_name=config[\"schema\"],\n","        workspace=workspace_id,\n","        client=fabric_client,\n","    )\n","\n","    # Deploy associated reports\n","    for report in config[\"reports\"]:\n","        P.create_or_replace_report_from_pbir(\n","            report_path=f\"{base_path}/Power BI Report/{report}.Report\",\n","            dataset_name=config[\"model\"],\n","            dataset_workspace=workspace_id,\n","            report_workspace=workspace_id,\n","            client=fabric_client,\n","        )"]},{"cell_type":"markdown","id":"4fc5bd16-bfc0-411a-b1d6-04a1bc20f4bb","metadata":{"nteract":{"transient":{"deleting":false}}},"source":["# Delete Git folder"]},{"cell_type":"code","execution_count":13,"id":"d6d874f0-8556-4ac6-9ab3-03eedc12b07a","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":true,"source_hidden":false},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"nteract":{"transient":{"deleting":false}}},"outputs":[],"source":["if is_fabric:\n","    L.delete_folder_from_lakehouse(\n","        lakehouse=lakehouse_name,\n","        path=ROOT_DOWNLOAD_FOLDER,\n","        workspace=workspace_id,\n","        client=fabric_client\n","    )"]},{"cell_type":"markdown","id":"dcbff0b4-d253-42cc-88cb-210d22b61604","metadata":{"nteract":{"transient":{"deleting":false}}},"source":["# Start Data Load"]},{"cell_type":"code","execution_count":null,"id":"a49aaaec-57a1-44c2-b5ff-4784b000bbc2","metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"nteract":{"transient":{"deleting":false}}},"outputs":[],"source":["if start_dataload:\n","    J.run_notebook_job(\n","        notebook_name=\"Cricsheet Orchestrator\",\n","        wait_for_completion=wait_for_dataload_completion,\n","        workspace=workspace_id,\n","        client=fabric_client\n","    )"]}],"metadata":{"dependencies":{"lakehouse":{}},"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.7"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"nteract":{"version":"nteract-front-end@1.0.0"},"spark_compute":{"compute_id":"/trident/default"},"synapse_widget":{"state":{},"version":"0.1"},"widgets":{}},"nbformat":4,"nbformat_minor":5}
